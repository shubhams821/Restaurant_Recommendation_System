{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## How the Restaurant Recommendation System Works?\n\nThe rapid growth in data collection has led to a new era of a data-driven world. Data is used to create more efficient systems and that’s where recommender systems come in.\n\nRecommendation systems are a type of information filtering systems because they improve the quality of search results and provide elements that are more relevant to the search item or that are related to the search history of the user.\n\nThese are active information filtering systems that personalize the information provided to a user based on their interests, relevance of the information, etc. Recommendation systems are widely used to recommend movies, items, restaurants, places to visit, items to buy, etc.\n\nThere are two types of recommendation systems:\n\n1. Content-based filtering\n2. Collaborative filtering\n\n","metadata":{}},{"cell_type":"markdown","source":"Importing the necessary Python Libraries:","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import r2_score\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.metrics.pairwise import linear_kernel\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"zomato_real=pd.read_csv(\"../input/zomato-bangalore-dataset/zomato.csv\")\nzomato_real.head() # prints the first 5 rows of the dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the next step is data cleaning and feature engineering for this step we need to do a lot of stuff with the data such as:\n\n1. Deleting Unnecessary Columns\n2. Removing the Duplicates\n3. Remove the NaN values from the dataset\n4. Changing the column names\n5. Data Transformations\n6. Data Cleaning\n7. Adjust the column names\nNow, let’s perform all the above steps in our data:","metadata":{}},{"cell_type":"code","source":"#Deleting Unnnecessary Columns\nzomato=zomato_real.drop(['url','dish_liked','phone'],axis=1) #Dropping the column \"dish_liked\", \"phone\", \"url\" and saving the new dataset as \"zomato\"\n\n#Removing the Duplicates\nzomato.duplicated().sum()\nzomato.drop_duplicates(inplace=True)\n\n#Remove the NaN values from the dataset\nzomato.isnull().sum()\nzomato.dropna(how='any',inplace=True)\n\n#Changing the column names\nzomato = zomato.rename(columns={'approx_cost(for two people)':'cost','listed_in(type)':'type', 'listed_in(city)':'city'})\n\n#Some Transformations\nzomato['cost'] = zomato['cost'].astype(str) #Changing the cost to string\nzomato['cost'] = zomato['cost'].apply(lambda x: x.replace(',','.')) #Using lambda function to replace ',' from cost\nzomato['cost'] = zomato['cost'].astype(float)\n#Removing '/5' from Rates\nzomato = zomato.loc[zomato.rate !='NEW']\nzomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\nremove_slash = lambda x: x.replace('/5', '') if type(x) == np.str else x\nzomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\n\n# Adjust the column names\nzomato.name = zomato.name.apply(lambda x:x.title())\nzomato.online_order.replace(('Yes','No'),(True, False),inplace=True)\nzomato.book_table.replace(('Yes','No'),(True, False),inplace=True)\n\n## Computing Mean Rating\nrestaurants = list(zomato['name'].unique())\nzomato['Mean Rating'] = 0\n\nfor i in range(len(restaurants)):\n    zomato['Mean Rating'][zomato['name'] == restaurants[i]] = zomato['rate'][zomato['name'] == restaurants[i]].mean()\n    \nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (1,5))\nzomato[['Mean Rating']] = scaler.fit_transform(zomato[['Mean Rating']]).round(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the next step is to perform some text preprocessing steps which include:\n\n1. Lower casing\n2. Removal of Punctuations\n3. Removal of Stopwords\n4. Removal of URLs\n5. Spelling correction\n\nNow let’s perform the above text preprocessing steps on the data:","metadata":{}},{"cell_type":"code","source":"## Lower Casing\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].str.lower()\n\n## Removal of Puctuations\nimport string\nPUNCT_TO_REMOVE = string.punctuation\ndef remove_punctuation(text):\n    \"\"\"custom function to remove the punctuation\"\"\"\n    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_punctuation(text))\n\n## Removal of Stopwords\nfrom nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\ndef remove_stopwords(text):\n    \"\"\"custom function to remove the stopwords\"\"\"\n    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_stopwords(text))\n\n## Removal of URLS\ndef remove_urls(text):\n    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n    return url_pattern.sub(r'', text)\n\nzomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_urls(text))\n\nzomato[['reviews_list', 'cuisines']].sample(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# RESTAURANT NAMES:\nrestaurant_names = list(zomato['name'].unique())\ndef get_top_words(column, top_nu_of_words, nu_of_word):\n    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n    bag_of_words = vec.fit_transform(column)\n    sum_words = bag_of_words.sum(axis=0)\n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    return words_freq[:top_nu_of_words]\n    \nzomato=zomato.drop(['address','rest_type', 'type', 'menu_item', 'votes'],axis=1)\nimport pandas\n\n# Randomly sample 60% of your dataframe\ndf_percent = zomato.sample(frac=0.5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF-IDF Vectorization\n\nTF-IDF (Term Frequency-Inverse Document Frequency) vectors for each document. This will give you a matrix where each column represents a word in the general vocabulary (all words that appear in at least one document) and each column represents a restaurant, as before.\n\nTF-IDF is the statistical method of assessing the meaning of a word in a given document. Now, I will use the TF-IDF vectorization on the dataset:","metadata":{}},{"cell_type":"code","source":"df_percent.set_index('name', inplace=True)\nindices = pd.Series(df_percent.index)\n\n# Creating tf-idf matrix\ntfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\ntfidf_matrix = tfidf.fit_transform(df_percent['reviews_list'])\n\ncosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now the last step for creating a Restaurant Recommendation System is to write a function that will recommend restaurants:","metadata":{}},{"cell_type":"code","source":"def recommend(name, cosine_similarities = cosine_similarities):\n    \n    # Create a list to put top restaurants\n    recommend_restaurant = []\n    \n    # Find the index of the hotel entered\n    idx = indices[indices == name].index[0]\n    \n    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n    \n    # Extract top 30 restaurant indexes with a similar cosine-sim value\n    top30_indexes = list(score_series.iloc[0:31].index)\n    \n    # Names of the top 30 restaurants\n    for each in top30_indexes:\n        recommend_restaurant.append(list(df_percent.index)[each])\n    \n    # Creating the new data set to show similar restaurants\n    df_new = pd.DataFrame(columns=['cuisines', 'Mean Rating', 'cost'])\n    \n    # Create the top 30 similar restaurants with some of their columns\n    for each in recommend_restaurant:\n        df_new = df_new.append(pd.DataFrame(df_percent[['cuisines','Mean Rating', 'cost']][df_percent.index == each].sample()))\n    \n    # Drop the same named restaurants and sort only the top 10 by the highest rating\n    df_new = df_new.drop_duplicates(subset=['cuisines','Mean Rating', 'cost'], keep=False)\n    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n    \n    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n    \n    return df_new\nrecommend('Pai Vihar')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}